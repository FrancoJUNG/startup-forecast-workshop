{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Module 2] Forecast 학습 데이터 준비 (Import Dataset)\n",
    "- 이 노트북에서는 Module1에서 생성한 target_time_series.csv 파일을 가지고 Forecast가 학습을 할 수 있게 하는 작업을 합니다. (This notebook has the following processes)\n",
    "\n",
    "- Create IAM role\n",
    "    - forecast 서비스가 다른 서비스(예: S3)에 접근시 사용할 역할을 생성 합니다.\n",
    "- Create a dataset group\n",
    "    - 전체 데이터 셋을 (Target Data Set, Related Data Set, Item Meta Data Set)을 담을 상위의 Dataset Group을 생성 합니다.\n",
    "- Create a schema for a dataset\n",
    "    - 여기서는 Target Data Set의 컬럼 정보, 컬럼 타입을 정의하는 스키마 파일을 정의해서 Forecast서비스가 어떠한 데이타가 입력 되는지를 알게 합니다.\n",
    "- Create the dataset\n",
    "    - 실제로 Target Data Set을 생성 합니다.\n",
    "- Attach the dataset to the dataset group\n",
    "    - 위에서 생성된 Target Data Set을 Dataset Group에 포함 시키는 작업을 합니다.\n",
    "- Upload the Target Data to S3\n",
    "    - [Module 1] 에서 만든 target_time_series.csv 파일을 S3에 업로드 합니다.\n",
    "- Create a dataset import job\n",
    "    - S3에 업로드 된 target_time_series.csv 파일을 Target Data Set에 Import하여 Forecast 서비스가 사용할 수 있게 합니다.\n",
    "    \n",
    "    \n",
    "* 이 과정은 약 5분 정도 소요 됩니다 **About 5 mins may be elapsed**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parmeters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DATASET_FREQUENCY 를 Day로 설정 합니다. 참고로 Week로 한다면 \"W\"로 지정 합니다. 또한 TIMESTAMP_FORMAT 를 yyyy-mm-dd 형식으로 지정 합니다.\n",
    "- Target Dataset 및 Target Dataset Group 의 이름을 지정 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FREQUENCY = \"D\" \n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd\"\n",
    "\n",
    "suffix = str(np.random.uniform())[4:9]\n",
    "\n",
    "\n",
    "# Enter a project name\n",
    "project = 'StoreItemDemand'\n",
    "\n",
    "\n",
    "\n",
    "target_datasetName= project+'DS' + suffix\n",
    "related_datasetName=project+'Related'+suffix\n",
    "datasetGroupName= project +'DSG'+ suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap-northeast-2\n"
     ]
    }
   ],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "     data = json.load(notebook_info)\n",
    "     resource_arn = data['ResourceArn']\n",
    "     region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region)\n",
    "forecast = session.client(service_name='forecast')\n",
    "forecast_query = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create role\n",
    "**Make sure that a role for SageMaker notebook instance has these policies attached such as AmazonSageMakerFullAccess, AmazonS3FullAccess, AmazonForecastFullAccess, IAMFullAccess**\n",
    "- ForecastRolePOC_XXX 역할을 생성하고, AmazonForecastFullAccess, AmazonS3FullAccess 이 두개의 Policy(권한)을 부여 합니다. ForecastRolePOC_XXX 는 Forecast 서비스가 다른 서비스(예: S3) 에 접근시 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::870180618679:role/ForecastRolePOC88082\n"
     ]
    }
   ],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "# Put the role name\n",
    "role_name = \"ForecastRolePOC\" + suffix\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"forecast.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like tåo use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/AmazonForecastFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DatasetGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:forecast:ap-northeast-2:870180618679:dataset-group/StoreItemDemandDSG88082'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_dataset_group_response = forecast.create_dataset_group(\n",
    "      DatasetGroupName= datasetGroupName,\n",
    "      Domain=\"CUSTOM\",\n",
    "     )\n",
    "datasetGroupArn = create_dataset_group_response['DatasetGroupArn']\n",
    "datasetGroupArn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset_group 의 생성 상태를 확인 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetGroupName': 'StoreItemDemandDSG88082',\n",
       " 'DatasetGroupArn': 'arn:aws:forecast:ap-northeast-2:870180618679:dataset-group/StoreItemDemandDSG88082',\n",
       " 'DatasetArns': [],\n",
       " 'Domain': 'CUSTOM',\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2020, 7, 12, 16, 23, 40, 631000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2020, 7, 12, 16, 23, 40, 631000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'a4f4bdeb-3f52-4538-aef3-55f036332d1a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sun, 12 Jul 2020 16:23:40 GMT',\n",
       "   'x-amzn-requestid': 'a4f4bdeb-3f52-4538-aef3-55f036332d1a',\n",
       "   'content-length': '274',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.describe_dataset_group(DatasetGroupArn=datasetGroupArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the schema of your dataset here. Make sure the order of columns matches the raw data files.\n",
    "target_schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"store\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },       \n",
    "      {\n",
    "         \"AttributeName\":\"target_value\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"store\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },       \n",
    "      {\n",
    "         \"AttributeName\":\"is_holidays\",\n",
    "         \"AttributeType\":\"integer\"\n",
    "      },\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetArn': 'arn:aws:forecast:ap-northeast-2:870180618679:dataset/StoreItemDemandDS88082',\n",
       " 'DatasetName': 'StoreItemDemandDS88082',\n",
       " 'Domain': 'CUSTOM',\n",
       " 'DatasetType': 'TARGET_TIME_SERIES',\n",
       " 'DataFrequency': 'D',\n",
       " 'Schema': {'Attributes': [{'AttributeName': 'timestamp',\n",
       "    'AttributeType': 'timestamp'},\n",
       "   {'AttributeName': 'item_id', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'store', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'target_value', 'AttributeType': 'float'}]},\n",
       " 'EncryptionConfig': {},\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2020, 7, 12, 16, 23, 40, 745000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2020, 7, 12, 16, 23, 40, 745000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '57959ebe-a631-483a-9108-29280c13a6e3',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sun, 12 Jul 2020 16:23:40 GMT',\n",
       "   'x-amzn-requestid': '57959ebe-a631-483a-9108-29280c13a6e3',\n",
       "   'content-length': '561',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=forecast.create_dataset(\n",
    "                    Domain=\"CUSTOM\",\n",
    "                    DatasetType='TARGET_TIME_SERIES',\n",
    "                    DatasetName=target_datasetName,\n",
    "                    DataFrequency=DATASET_FREQUENCY, \n",
    "                    Schema = target_schema\n",
    ")\n",
    "target_datasetArn = response['DatasetArn']\n",
    "forecast.describe_dataset(DatasetArn=target_datasetArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetArn': 'arn:aws:forecast:ap-northeast-2:870180618679:dataset/StoreItemDemandRelated88082',\n",
       " 'DatasetName': 'StoreItemDemandRelated88082',\n",
       " 'Domain': 'CUSTOM',\n",
       " 'DatasetType': 'RELATED_TIME_SERIES',\n",
       " 'DataFrequency': 'D',\n",
       " 'Schema': {'Attributes': [{'AttributeName': 'timestamp',\n",
       "    'AttributeType': 'timestamp'},\n",
       "   {'AttributeName': 'item_id', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'store', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'is_holidays', 'AttributeType': 'integer'}]},\n",
       " 'EncryptionConfig': {},\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2020, 7, 12, 16, 23, 40, 891000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2020, 7, 12, 16, 23, 40, 891000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '9057852e-9d83-4a33-b3e5-6fb48ebbaf19',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sun, 12 Jul 2020 16:23:40 GMT',\n",
       "   'x-amzn-requestid': '9057852e-9d83-4a33-b3e5-6fb48ebbaf19',\n",
       "   'content-length': '573',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=forecast.create_dataset(\n",
    "                    Domain=\"CUSTOM\",\n",
    "                    DatasetType='RELATED_TIME_SERIES',\n",
    "                    DatasetName=related_datasetName,\n",
    "                    DataFrequency=DATASET_FREQUENCY, \n",
    "                    Schema = related_schema\n",
    ")\n",
    "related_datasetArn = response['DatasetArn']\n",
    "forecast.describe_dataset(DatasetArn=related_datasetArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach the target time series dataset to the DatasetGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'af9254c5-632a-4f48-a532-4234b3698175',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Sun, 12 Jul 2020 16:23:40 GMT',\n",
       "   'x-amzn-requestid': 'af9254c5-632a-4f48-a532-4234b3698175',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach the Dataset to the Dataset Group:\n",
    "forecast.update_dataset_group(\n",
    "    DatasetGroupArn=datasetGroupArn, \n",
    "    DatasetArns=[target_datasetArn,\n",
    "                 related_datasetArn])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket name is  sagemaker-ap-northeast-2-870180618679\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# if you want, replace with a name of your S3 bucket\n",
    "bucket_name = sagemaker.Session().default_bucket()  \n",
    "\n",
    "if s3_resource.Bucket(bucket_name).creation_date is None:\n",
    "    # bucket is not existing \n",
    "    s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})    \n",
    "else: \n",
    "    # Bucket exists\n",
    "    print(\"bucket name is \", bucket_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload target data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Module 1 에서 생성한 target_time_series.csv 파일을 S3에 업로드 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-870180618679/StoreItemDemand/target_time_series.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload Target File under a bucket folder\n",
    "bucket_folder = project\n",
    "s3_file_path = bucket_folder + \"/\" + target_time_series_filename\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(s3_file_path).upload_file(target_time_series_path)\n",
    "target_s3DataPath = \"s3://\"+bucket_name + \"/\" + s3_file_path\n",
    "target_s3DataPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-870180618679/StoreItemDemand/related_holidays.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_file_path = bucket_folder + \"/\" + related_time_series_filename\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(s3_file_path).upload_file(related_time_series_path)\n",
    "related_s3DataPath = \"s3://\"+bucket_name + \"/\" + s3_file_path\n",
    "related_s3DataPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset_import_job used to download dataset from S3\n",
    "- S3에서 Target Data Set으로 데이터를 Import 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can call import the dataset\n",
    "datasetImportJobName = 'DATASET_IMPORT_JOB_TARGET' + suffix\n",
    "response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n",
    "                                                          DatasetArn=target_datasetArn,\n",
    "                                                          DataSource= {\n",
    "                                                              \"S3Config\" : {\n",
    "                                                                 \"Path\":target_s3DataPath,\n",
    "                                                                 \"RoleArn\": role_arn\n",
    "                                                              } \n",
    "                                                          },\n",
    "                                                          TimestampFormat=TIMESTAMP_FORMAT\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:forecast:ap-northeast-2:870180618679:dataset-import-job/StoreItemDemandDS88082/DATASET_IMPORT_JOB_TARGET88082\n"
     ]
    }
   ],
   "source": [
    "target_import_job_arn=response['DatasetImportJobArn']\n",
    "print(target_import_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can call import the dataset\n",
    "datasetImportJobName = 'DATASET_IMPORT_JOB_RELATED' + suffix\n",
    "response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n",
    "                                                          DatasetArn=related_datasetArn,\n",
    "                                                          DataSource= {\n",
    "                                                              \"S3Config\" : {\n",
    "                                                                 \"Path\":related_s3DataPath,\n",
    "                                                                 \"RoleArn\": role_arn\n",
    "                                                              } \n",
    "                                                          },\n",
    "                                                          TimestampFormat=TIMESTAMP_FORMAT\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:forecast:ap-northeast-2:870180618679:dataset-import-job/StoreItemDemandRelated88082/DATASET_IMPORT_JOB_RELATED88082\n"
     ]
    }
   ],
   "source": [
    "related_import_job_arn=response['DatasetImportJobArn']\n",
    "print(related_import_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_import_status:CREATE_PENDING\n",
      "related_import_status:CREATE_PENDING\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:CREATE_IN_PROGRESS\n",
      "related_import_status:CREATE_IN_PROGRESS\n",
      "target_import_status:ACTIVE\n",
      "related_import_status:ACTIVE\n",
      "CPU times: user 112 ms, sys: 953 µs, total: 113 ms\n",
      "Wall time: 8min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "while True:\n",
    "    target_Status = forecast.describe_dataset_import_job(DatasetImportJobArn=target_import_job_arn)['Status']\n",
    "    related_Status = forecast.describe_dataset_import_job(DatasetImportJobArn=related_import_job_arn)['Status']\n",
    "    print(\"target_import_status:{}\".format(target_Status))\n",
    "    print(\"related_import_status:{}\".format(related_Status))\n",
    "    if (target_Status != 'ACTIVE' and target_Status != 'CREATE_FAILED') or (related_Status != 'ACTIVE' and related_Status != 'CREATE_FAILED') :\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'project' (str)\n",
      "Stored 'suffix' (str)\n",
      "Stored 'region' (str)\n",
      "Stored 'target_import_job_arn' (str)\n",
      "Stored 'related_import_job_arn' (str)\n",
      "Stored 'datasetGroupArn' (str)\n",
      "Stored 'target_datasetArn' (str)\n",
      "Stored 'related_datasetArn' (str)\n",
      "Stored 'bucket_name' (str)\n",
      "Stored 'bucket_folder' (str)\n",
      "Stored 'role_arn' (str)\n",
      "Stored 'role_name' (str)\n",
      "Stored 'validation_stores_sales' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store project\n",
    "%store suffix\n",
    "%store region\n",
    "%store target_import_job_arn\n",
    "%store related_import_job_arn\n",
    "%store datasetGroupArn\n",
    "%store target_datasetArn\n",
    "%store related_datasetArn\n",
    "%store bucket_name\n",
    "%store bucket_folder\n",
    "%store role_arn\n",
    "%store role_name\n",
    "%store validation_stores_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
